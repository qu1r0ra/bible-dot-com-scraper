{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3245aa99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c09a6ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote CSV /Users/armina/Documents/GitHub/bible-dot-com-scraper/parallel_corpora/cebuano_tausug_verse.csv\n"
     ]
    }
   ],
   "source": [
    "Cebuano_dir = Path(\"/Users/armina/Documents/GitHub/bible-dot-com-scraper/parser/yna/parsed/Cebuano\")\n",
    "Tausug_dir  = Path(\"/Users/armina/Documents/GitHub/bible-dot-com-scraper/parser/yna/parsed/Tausug\")\n",
    "\n",
    "out_csv   = Path(\"cebuano_tausug_verse.csv\")\n",
    "\n",
    "DEDUP_STRATEGY = \"first\" \n",
    "\n",
    "def load_language_folder(folder: Path, lang_name: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load all CSV files under `folder`, keep relevant columns, and return a DataFrame\n",
    "    where the verse text column is renamed to the language name (e.g., 'Cebuano', 'Tausug').\n",
    "    \"\"\"\n",
    "    csv_files = sorted(folder.glob(\"*.csv\"))\n",
    "    if not csv_files:\n",
    "        print(f\"[WARN] No CSV files found in {folder}\")\n",
    "        return pd.DataFrame(columns=[\"usfm\",\"book\",\"chapter\",\"verse\",lang_name])\n",
    "\n",
    "    frames = []\n",
    "    for fp in csv_files:\n",
    "        try:\n",
    "            df = pd.read_csv(fp, dtype=str, encoding=\"utf-8\")\n",
    "        except UnicodeDecodeError:\n",
    "            df = pd.read_csv(fp, dtype=str, encoding_errors=\"ignore\")\n",
    "\n",
    "        needed = [\"usfm\",\"book\",\"chapter\",\"verse\",\"text\"]\n",
    "        missing = [c for c in needed if c not in df.columns]\n",
    "        if missing:\n",
    "            print(f\"[WARN] {fp} is missing columns {missing}; skipping.\")\n",
    "            continue\n",
    "\n",
    "        df = df[needed].copy()\n",
    "        frames.append(df)\n",
    "\n",
    "    if not frames:\n",
    "        return pd.DataFrame(columns=[\"usfm\",\"book\",\"chapter\",\"verse\",lang_name])\n",
    "\n",
    "    df_all = pd.concat(frames, ignore_index=True)\n",
    "\n",
    "    if DEDUP_STRATEGY == \"join\":\n",
    "        agg = {\"text\": lambda s: \" | \".join(pd.Series(s, dtype=str).dropna().unique())}\n",
    "        df_all = (\n",
    "            df_all.groupby([\"usfm\",\"book\",\"chapter\",\"verse\"], as_index=False)\n",
    "                  .agg(agg)\n",
    "        )\n",
    "    else:  \n",
    "        df_all = df_all.drop_duplicates(subset=[\"usfm\",\"book\",\"chapter\",\"verse\"], keep=\"first\")\n",
    "\n",
    "    df_all = df_all.rename(columns={\"text\": lang_name})\n",
    "\n",
    "    for col in [\"chapter\",\"verse\"]:\n",
    "        df_all[col + \"_num\"] = pd.to_numeric(df_all[col], errors=\"coerce\")\n",
    "\n",
    "    return df_all\n",
    "\n",
    "df_bik = load_language_folder(Cebuano_dir, \"Cebuano\")\n",
    "df_tag = load_language_folder(Tausug_dir,  \"Tausug\")\n",
    "\n",
    "on_keys = [\"usfm\",\"book\",\"chapter\",\"verse\"]\n",
    "merged = pd.merge(\n",
    "    df_bik[on_keys + [\"Cebuano\",\"chapter_num\",\"verse_num\"]],\n",
    "    df_tag[on_keys + [\"Tausug\",\"chapter_num\",\"verse_num\"]],\n",
    "    on=on_keys,\n",
    "    how=\"outer\",\n",
    "    suffixes=(\"\", \"_y\")\n",
    ")\n",
    "\n",
    "merged[\"chapter_num\"] = merged[\"chapter_num\"].combine_first(merged.pop(\"chapter_num_y\"))\n",
    "merged[\"verse_num\"]   = merged[\"verse_num\"].combine_first(merged.pop(\"verse_num_y\"))\n",
    "\n",
    "for col in [\"Cebuano\", \"Tausug\"]:\n",
    "    if col in merged.columns:\n",
    "        merged[col] = merged[col].replace(r\"^\\s*$\", pd.NA, regex=True).fillna(\"N/A\")\n",
    "\n",
    "merged = merged.sort_values([\"book\",\"chapter_num\",\"verse_num\",\"usfm\"], kind=\"mergesort\")\n",
    "merged = merged[[\"usfm\",\"book\",\"chapter\",\"verse\",\"Cebuano\",\"Tausug\"]]\n",
    "\n",
    "merged.to_csv(out_csv, index=False)\n",
    "print(f\"Wrote CSV {out_csv.resolve()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ce137cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Wrote 70758 lines to tagalog_kapampangan_verse.txt\n",
      "Verses total: 35379 | missing in first: 1 | missing in second: 27\n"
     ]
    }
   ],
   "source": [
    "lang1_dir = Path(\"/Users/armina/Documents/GitHub/bible-dot-com-scraper/parser/cj/parsed/Tagalog\")  \n",
    "lang2_dir = Path(\"/Users/armina/Documents/GitHub/bible-dot-com-scraper/parser/trish/parsed/Kapampangan\")      \n",
    "out_txt   = Path(\"tagalog_kapampangan_verse.txt\")\n",
    "DEDUP_STRATEGY = \"first\"  \n",
    "MISSING = '\"N/A\"'\n",
    "\n",
    "LINE_RE = re.compile(r'^\\s*([0-9A-Z]+\\.\\d+\\.\\d+)\\s+(.*\\S)\\s*$') \n",
    "\n",
    "def parse_txt_file(fp: Path):\n",
    "    d = {}\n",
    "    with fp.open(\"r\", encoding=\"utf-8-sig\", errors=\"replace\") as f:\n",
    "        for raw in f:\n",
    "            m = LINE_RE.match(raw)\n",
    "            if not m:\n",
    "                continue\n",
    "            usfm_id, text = m.group(1), m.group(2).strip()\n",
    "            if usfm_id in d:\n",
    "                if DEDUP_STRATEGY == \"join\" and text not in d[usfm_id]:\n",
    "                    d[usfm_id] = d[usfm_id] + \" | \" + text\n",
    "            else:\n",
    "                d[usfm_id] = text\n",
    "    return d\n",
    "\n",
    "def load_folder(folder: Path):\n",
    "    combined = {}\n",
    "    for fp in sorted(folder.glob(\"*.txt\")):\n",
    "        part = parse_txt_file(fp)\n",
    "        for k, v in part.items():\n",
    "            if k in combined:\n",
    "                if DEDUP_STRATEGY == \"join\" and v not in combined[k]:\n",
    "                    combined[k] = combined[k] + \" | \" + v\n",
    "            else:\n",
    "                combined[k] = v\n",
    "    return combined\n",
    "\n",
    "def usfm_sort_key(usfm: str):\n",
    "    parts = usfm.split(\".\")\n",
    "    book = parts[0] if parts else \"\"\n",
    "    chap = int(parts[1]) if len(parts) > 1 and parts[1].isdigit() else 0\n",
    "    verse = int(parts[2]) if len(parts) > 2 and parts[2].isdigit() else 0\n",
    "    return (book, chap, verse)\n",
    "\n",
    "# main\n",
    "lang1 = load_folder(lang1_dir)\n",
    "lang2 = load_folder(lang2_dir)\n",
    "\n",
    "all_usfm = sorted(set(lang1.keys()) | set(lang2.keys()), key=usfm_sort_key)\n",
    "\n",
    "lines_out = []\n",
    "for u in all_usfm:\n",
    "    t1 = lang1.get(u, MISSING)\n",
    "    t2 = lang2.get(u, MISSING)\n",
    "    lines_out.append(f\"{u} {t1}\")\n",
    "    lines_out.append(f\"{u} {t2}\")\n",
    "\n",
    "out_txt.write_text(\"\\n\".join(lines_out) + \"\\n\", encoding=\"utf-8\")\n",
    "\n",
    "print(f\"Done. Wrote {len(lines_out)} lines to {out_txt}\")\n",
    "print(f\"Verses total: {len(all_usfm)} | missing in first: {sum(lang1.get(u) is None for u in all_usfm)} | \"\n",
    "      f\"missing in second: {sum(lang2.get(u) is None for u in all_usfm)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
